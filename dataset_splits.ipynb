{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "8VMVc_9n3lgP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymybj3GK3gJ-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Config\n"
      ],
      "metadata": {
        "id": "rxU3Vase3q3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = None\n",
        "output_dir = None\n",
        "split_ratios = {\"train\": 0.8, \"val\": 0.2}\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "CGNg9bXz3p7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split ID's"
      ],
      "metadata": {
        "id": "FUuzRAlz31Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Excel file\n",
        "excel_file_path = base_dir / \"sand_task_1.xlsx\"\n",
        "metadata = pd.read_excel(excel_file_path, dtype={\"ID\": str})\n",
        "\n",
        "# separate participants by class\n",
        "class_1 = metadata[metadata['Class'] == 1]\n",
        "class_2 = metadata[metadata['Class'] == 2]\n",
        "class_3 = metadata[metadata['Class'] == 3]\n",
        "class_4 = metadata[metadata['Class'] == 4]\n",
        "class_5 = metadata[metadata['Class'] == 5]\n",
        "\n",
        "print('Class 1:')\n",
        "print(class_1)\n",
        "\n",
        "# Split ID's\n",
        "c1_shuffled = class_1.sample(frac=1).reset_index(drop=True)\n",
        "c2_shuffled = class_2.sample(frac=1).reset_index(drop=True)\n",
        "c3_shuffled = class_3.sample(frac=1).reset_index(drop=True)\n",
        "c4_shuffled = class_4.sample(frac=1).reset_index(drop=True)\n",
        "c5_shuffled = class_5.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print('\\nClass 1 shuffled:')\n",
        "print(c1_shuffled)\n",
        "\n",
        "# split up each class for train / val\n",
        "def split(data, train_split=0.8):\n",
        "    n_train = int(len(data) * train_split)\n",
        "    train = data.iloc[:n_train]\n",
        "    val   = data.iloc[n_train:]\n",
        "    return train, val\n",
        "\n",
        "# split up each class into train and val\n",
        "c1_train, c1_val = split(c1_shuffled, split_ratios['train'])\n",
        "c2_train, c2_val = split(c2_shuffled, split_ratios['train'])\n",
        "c3_train, c3_val = split(c3_shuffled, split_ratios['train'])\n",
        "c4_train, c4_val = split(c4_shuffled, split_ratios['train'])\n",
        "c5_train, c5_val = split(c5_shuffled, split_ratios['train'])\n",
        "\n",
        "# combine training and val dataframes\n",
        "train_mixed = pd.concat([c1_train, c2_train, c3_train, c4_train, c5_train], ignore_index=True)\n",
        "val_mixed = pd.concat([c1_val, c2_val, c3_val, c4_val, c5_val], ignore_index=True)\n",
        "\n",
        "# shuffle the order of each dataset\n",
        "train_mixed_shuffled = train_mixed.sample(frac=1).reset_index(drop=True)\n",
        "val_mixed_shuffled = val_mixed.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# visual check of distributions of each dataset\n",
        "\n",
        "print('\\ndistribution of class in train set:')\n",
        "print(f'class 1: {len(c1_train) / len(train_mixed_shuffled) * 100}%')\n",
        "print(f'class 2: {len(c2_train) / len(train_mixed_shuffled) * 100}%')\n",
        "print(f'class 3: {len(c3_train) / len(train_mixed_shuffled) * 100}%')\n",
        "print(f'class 4: {len(c4_train) / len(train_mixed_shuffled) * 100}%')\n",
        "print(f'class 5: {len(c5_train) / len(train_mixed_shuffled) * 100}%')\n",
        "\n",
        "print('\\ndistribution of class in val set:')\n",
        "print(f'class 1: {len(c1_val) / len(val_mixed_shuffled) * 100}%')\n",
        "print(f'class 2: {len(c2_val) / len(val_mixed_shuffled) * 100}%')\n",
        "print(f'class 3: {len(c3_val) / len(val_mixed_shuffled) * 100}%')\n",
        "print(f'class 4: {len(c4_val) / len(val_mixed_shuffled) * 100}%')\n",
        "print(f'class 5: {len(c5_val) / len(val_mixed_shuffled) * 100}%')\n",
        "\n",
        "print('\\ndistribution of original dataset:')\n",
        "print(f'class 1: {len(class_1) / len(metadata) * 100}%')\n",
        "print(f'class 2: {len(class_2) / len(metadata) * 100}%')\n",
        "print(f'class 3: {len(class_3) / len(metadata) * 100}%')\n",
        "print(f'class 4: {len(class_4) / len(metadata) * 100}%')\n",
        "print(f'class 5: {len(class_5) / len(metadata) * 100}%')\n",
        "\n",
        "# make selections and convert to list\n",
        "train_ids = train_mixed_shuffled['ID'].tolist()\n",
        "val_ids   = val_mixed_shuffled['ID'].tolist()\n",
        "\n",
        "splits = {\"train\": train_ids, \"val\": val_ids}\n",
        "print(f\"\\nTotal subjects: {len(metadata)} | Train: {len(train_ids)} | Val: {len(val_ids)}\")\n",
        "\n",
        "# visual check of first few participants\n",
        "\n",
        "print('\\ntraining set head:')\n",
        "print(train_mixed_shuffled.sort_values(by='ID').head())\n",
        "\n",
        "print('\\nval set head:')\n",
        "print(val_mixed_shuffled.sort_values(by='ID').head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTjGH2cG31l6",
        "outputId": "f4784695-61af-47fe-bf91-5b270f82121d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1:\n",
            "        ID  Age Sex  Class\n",
            "60   ID077   72   F      1\n",
            "86   ID111   53   F      1\n",
            "107  ID138   60   F      1\n",
            "171  ID213   72   F      1\n",
            "210  ID261   68   M      1\n",
            "253  ID316   60   M      1\n",
            "\n",
            "Class 1 shuffled:\n",
            "      ID  Age Sex  Class\n",
            "0  ID111   53   F      1\n",
            "1  ID213   72   F      1\n",
            "2  ID316   60   M      1\n",
            "3  ID261   68   M      1\n",
            "4  ID138   60   F      1\n",
            "5  ID077   72   F      1\n",
            "\n",
            "distribution of class in train set:\n",
            "class 1: 1.8691588785046727%\n",
            "class 2: 9.345794392523365%\n",
            "class 3: 21.02803738317757%\n",
            "class 4: 28.037383177570092%\n",
            "class 5: 39.719626168224295%\n",
            "\n",
            "distribution of class in val set:\n",
            "class 1: 3.4482758620689653%\n",
            "class 2: 10.344827586206897%\n",
            "class 3: 20.689655172413794%\n",
            "class 4: 27.586206896551722%\n",
            "class 5: 37.93103448275862%\n",
            "\n",
            "distribution of original dataset:\n",
            "class 1: 2.2058823529411766%\n",
            "class 2: 9.558823529411764%\n",
            "class 3: 20.955882352941178%\n",
            "class 4: 27.941176470588236%\n",
            "class 5: 39.338235294117645%\n",
            "\n",
            "Total subjects: 272 | Train: 214 | Val: 58\n",
            "\n",
            "training set head:\n",
            "        ID  Age Sex  Class\n",
            "137  ID000   80   M      5\n",
            "88   ID001   61   F      5\n",
            "203  ID002   51   F      4\n",
            "78   ID003   59   M      3\n",
            "166  ID005   80   F      5\n",
            "\n",
            "val set head:\n",
            "       ID  Age Sex  Class\n",
            "56  ID027   78   M      4\n",
            "37  ID047   76   M      5\n",
            "0   ID050   73   F      2\n",
            "25  ID059   60   M      4\n",
            "14  ID067   71   M      5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move Files"
      ],
      "metadata": {
        "id": "zpCh6j114KCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create split folders\n",
        "for split in tqdm(splits):\n",
        "    for task_folder in base_dir.iterdir():\n",
        "        if task_folder.is_dir():\n",
        "            out_dir = output_dir / split / task_folder.name\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Move files\n",
        "for task_folder in tqdm(base_dir.iterdir()):\n",
        "    if not task_folder.is_dir():\n",
        "        continue\n",
        "    for wav_path in task_folder.glob(\"*.wav\"):\n",
        "        subj_id = wav_path.name.split(\"_\")[0]\n",
        "        for split_name, ids in splits.items():\n",
        "            if subj_id in ids:\n",
        "                dest = output_dir / split_name / task_folder.name / wav_path.name\n",
        "                dest.parent.mkdir(parents=True, exist_ok=True)  # ensure folder exists\n",
        "                shutil.copyfile(wav_path, dest)  # copy the file\n",
        "                break\n",
        "\n",
        "print(\"âœ… Dataset split complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIESp_Fw4Ji-",
        "outputId": "390d68dd-4fd7-452d-cb37-12634ed51150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 39.18it/s]\n",
            "9it [02:10, 14.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset split complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}